{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, SimpleRNN, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('alice.txt', 'r') as f:\n",
    "    texts = f.read().split('\\n')\n",
    "    texts = ' '.join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size 86\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(list(set([c for c in texts])))\n",
    "n_vocab = len(vocab)\n",
    "c2i = {c:i for i, c in enumerate(vocab)}\n",
    "i2c = {i:c for i, c in enumerate(vocab)}\n",
    "print('vocab_size', n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate training data\n",
    "seq_len = 10\n",
    "step = 1\n",
    "input_chars, label_chars = [], []\n",
    "# given 'this is a book'\n",
    "# input: 'this is a boo'\n",
    "# output: 'k'\n",
    "for i in range(0, len(texts)-seq_len, step):\n",
    "    input_chars.append(texts[i:i+seq_len])\n",
    "    label_chars.append(texts[i+seq_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize\n",
    "N = len(input_chars)\n",
    "X = np.zeros((N, seq_len, n_vocab)) # one-hot representaiton\n",
    "Y = np.zeros((N, n_vocab))\n",
    "for i, x in enumerate(input_chars):\n",
    "    for t, ch in enumerate(x):\n",
    "        X[i, t, c2i[ch]] = 1\n",
    "    Y[i, c2i[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10, 86)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 64)                9664      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 86)                5590      \n",
      "=================================================================\n",
      "Total params: 15,254\n",
      "Trainable params: 15,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "hidden_size = 64\n",
    "batch_size = 128\n",
    "n_epoch = 40\n",
    "\n",
    "char_inputs = Input(shape=(seq_len, n_vocab))\n",
    "hidden = SimpleRNN(hidden_size, unroll=True)(char_inputs)\n",
    "char_output = Dense(n_vocab, activation='softmax')(hidden)\n",
    "model = Model(char_inputs, char_output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 131045 samples, validate on 32762 samples\n",
      "Epoch 1/40\n",
      "131045/131045 [==============================] - 3s 21us/step - loss: 2.6632 - acc: 0.3024 - val_loss: 2.6195 - val_acc: 0.3280\n",
      "Epoch 2/40\n",
      "131045/131045 [==============================] - 3s 23us/step - loss: 2.1728 - acc: 0.4064 - val_loss: 2.4964 - val_acc: 0.3518\n",
      "Epoch 3/40\n",
      "131045/131045 [==============================] - 3s 21us/step - loss: 2.0270 - acc: 0.4396 - val_loss: 2.4510 - val_acc: 0.3709\n",
      "Epoch 4/40\n",
      "131045/131045 [==============================] - 2s 19us/step - loss: 1.9434 - acc: 0.4571 - val_loss: 2.4161 - val_acc: 0.3743\n",
      "Epoch 5/40\n",
      "131045/131045 [==============================] - 2s 19us/step - loss: 1.8841 - acc: 0.4705 - val_loss: 2.3885 - val_acc: 0.3839\n",
      "Epoch 6/40\n",
      "131045/131045 [==============================] - 3s 22us/step - loss: 1.8392 - acc: 0.4811 - val_loss: 2.3633 - val_acc: 0.3855\n",
      "Epoch 7/40\n",
      "131045/131045 [==============================] - 3s 20us/step - loss: 1.8024 - acc: 0.4912 - val_loss: 2.3611 - val_acc: 0.3890\n",
      "Epoch 8/40\n",
      "131045/131045 [==============================] - 3s 20us/step - loss: 1.7718 - acc: 0.4978 - val_loss: 2.3426 - val_acc: 0.3910\n",
      "Epoch 9/40\n",
      "131045/131045 [==============================] - 3s 20us/step - loss: 1.7459 - acc: 0.5027 - val_loss: 2.3442 - val_acc: 0.3971\n",
      "Epoch 10/40\n",
      "131045/131045 [==============================] - 3s 22us/step - loss: 1.7234 - acc: 0.5083 - val_loss: 2.3164 - val_acc: 0.4030\n",
      "Epoch 11/40\n",
      "131045/131045 [==============================] - 3s 21us/step - loss: 1.7035 - acc: 0.5130 - val_loss: 2.3065 - val_acc: 0.4007\n",
      "Epoch 12/40\n",
      "131045/131045 [==============================] - 3s 20us/step - loss: 1.6858 - acc: 0.5162 - val_loss: 2.3075 - val_acc: 0.4088\n",
      "Epoch 13/40\n",
      "131045/131045 [==============================] - 3s 22us/step - loss: 1.6707 - acc: 0.5200 - val_loss: 2.3094 - val_acc: 0.4036\n",
      "Epoch 14/40\n",
      "131045/131045 [==============================] - 3s 23us/step - loss: 1.6570 - acc: 0.5225 - val_loss: 2.2915 - val_acc: 0.4122\n",
      "Epoch 15/40\n",
      "131045/131045 [==============================] - 3s 22us/step - loss: 1.6440 - acc: 0.5267 - val_loss: 2.2916 - val_acc: 0.4111\n",
      "Epoch 16/40\n",
      "131045/131045 [==============================] - 3s 20us/step - loss: 1.6323 - acc: 0.5291 - val_loss: 2.2792 - val_acc: 0.4132\n",
      "Epoch 17/40\n",
      "131045/131045 [==============================] - 3s 19us/step - loss: 1.6224 - acc: 0.5313 - val_loss: 2.2828 - val_acc: 0.4117\n",
      "Epoch 18/40\n",
      "131045/131045 [==============================] - 3s 19us/step - loss: 1.6113 - acc: 0.5357 - val_loss: 2.2795 - val_acc: 0.4144\n",
      "Epoch 19/40\n",
      "131045/131045 [==============================] - 3s 22us/step - loss: 1.6022 - acc: 0.5361 - val_loss: 2.2814 - val_acc: 0.4154\n",
      "Epoch 20/40\n",
      "131045/131045 [==============================] - 3s 20us/step - loss: 1.5934 - acc: 0.5380 - val_loss: 2.2826 - val_acc: 0.4199\n",
      "Epoch 21/40\n",
      "131045/131045 [==============================] - 2s 19us/step - loss: 1.5865 - acc: 0.5410 - val_loss: 2.2689 - val_acc: 0.4241\n",
      "Epoch 22/40\n",
      "131045/131045 [==============================] - 3s 25us/step - loss: 1.5793 - acc: 0.5421 - val_loss: 2.2674 - val_acc: 0.4200\n",
      "Epoch 23/40\n",
      "131045/131045 [==============================] - 3s 22us/step - loss: 1.5729 - acc: 0.5435 - val_loss: 2.2694 - val_acc: 0.4241\n",
      "Epoch 24/40\n",
      "131045/131045 [==============================] - 3s 24us/step - loss: 1.5659 - acc: 0.5450 - val_loss: 2.2685 - val_acc: 0.4210\n",
      "Epoch 25/40\n",
      "131045/131045 [==============================] - 3s 23us/step - loss: 1.5606 - acc: 0.5463 - val_loss: 2.2689 - val_acc: 0.4180\n",
      "Epoch 26/40\n",
      "131045/131045 [==============================] - 3s 23us/step - loss: 1.5542 - acc: 0.5481 - val_loss: 2.2616 - val_acc: 0.4219\n",
      "Epoch 27/40\n",
      "131045/131045 [==============================] - 3s 22us/step - loss: 1.5497 - acc: 0.5488 - val_loss: 2.2766 - val_acc: 0.4193\n",
      "Epoch 28/40\n",
      "131045/131045 [==============================] - 3s 24us/step - loss: 1.5441 - acc: 0.5499 - val_loss: 2.2711 - val_acc: 0.4180\n",
      "Epoch 29/40\n",
      "131045/131045 [==============================] - 3s 25us/step - loss: 1.5393 - acc: 0.5512 - val_loss: 2.2737 - val_acc: 0.4202\n",
      "Epoch 30/40\n",
      "131045/131045 [==============================] - 3s 21us/step - loss: 1.5348 - acc: 0.5529 - val_loss: 2.2621 - val_acc: 0.4216\n",
      "Epoch 31/40\n",
      "131045/131045 [==============================] - 3s 24us/step - loss: 1.5304 - acc: 0.5532 - val_loss: 2.2694 - val_acc: 0.4192\n",
      "Epoch 32/40\n",
      "131045/131045 [==============================] - 2s 19us/step - loss: 1.5261 - acc: 0.5546 - val_loss: 2.2725 - val_acc: 0.4240\n",
      "Epoch 33/40\n",
      "131045/131045 [==============================] - 3s 20us/step - loss: 1.5222 - acc: 0.5555 - val_loss: 2.2734 - val_acc: 0.4244\n",
      "Epoch 34/40\n",
      "131045/131045 [==============================] - 3s 26us/step - loss: 1.5188 - acc: 0.5569 - val_loss: 2.2634 - val_acc: 0.4224\n",
      "Epoch 35/40\n",
      "131045/131045 [==============================] - 4s 27us/step - loss: 1.5138 - acc: 0.5576 - val_loss: 2.2727 - val_acc: 0.4217\n",
      "Epoch 36/40\n",
      "131045/131045 [==============================] - 3s 26us/step - loss: 1.5111 - acc: 0.5585 - val_loss: 2.2620 - val_acc: 0.4296\n",
      "Epoch 37/40\n",
      "131045/131045 [==============================] - 3s 19us/step - loss: 1.5080 - acc: 0.5588 - val_loss: 2.2790 - val_acc: 0.4221\n",
      "Epoch 38/40\n",
      "131045/131045 [==============================] - 3s 19us/step - loss: 1.5037 - acc: 0.5604 - val_loss: 2.2693 - val_acc: 0.4282\n",
      "Epoch 39/40\n",
      "131045/131045 [==============================] - 3s 24us/step - loss: 1.5018 - acc: 0.5597 - val_loss: 2.2742 - val_acc: 0.4277\n",
      "Epoch 40/40\n",
      "131045/131045 [==============================] - 3s 23us/step - loss: 1.4982 - acc: 0.5618 - val_loss: 2.2804 - val_acc: 0.4273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcb6d77f908>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=n_epoch,\n",
    "          validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: ﻿Project G\n",
      "predict: r\n",
      "label: u\n",
      "input: Project Gu\n",
      "predict: t\n",
      "label: t\n",
      "input: roject Gut\n",
      "predict: e\n",
      "label: e\n",
      "input: oject Gute\n",
      "predict: n\n",
      "label: n\n",
      "input: ject Guten\n",
      "predict: t\n",
      "label: b\n",
      "input: ect Gutenb\n",
      "predict: l\n",
      "label: e\n",
      "input: ct Gutenbe\n",
      "predict: r\n",
      "label: r\n",
      "input: t Gutenber\n",
      "predict:  \n",
      "label: g\n",
      "input:  Gutenberg\n",
      "predict: e\n",
      "label: ’\n",
      "input: Gutenberg’\n",
      "predict: t\n",
      "label: s\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "n_pred = 10\n",
    "for i in range(n_pred):\n",
    "    testX = X[i]\n",
    "    testX = np.reshape(testX, (1, testX.shape[0], testX.shape[1]))\n",
    "    pred = model.predict(testX)\n",
    "    ypred = i2c[np.argmax(pred)]\n",
    "    print('input:', input_chars[i])\n",
    "    print('predict:', ypred)\n",
    "    print('label:', label_chars[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
